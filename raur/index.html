<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta charset="utf-8"><meta name="generator" content="ReSpec 25.3.1"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><style>/* dfn popup panel that list all local references to a dfn */
dfn {
  cursor: pointer;
}

.dfn-panel {
  position: absolute;
  left: var(--left); /* set via JS */
  top: var(--top); /* set via JS */
  z-index: 35;
  height: auto;
  width: max-content;
  max-width: 300px;
  max-height: 500px;
  overflow: auto;
  padding: 0.5em 0.75em;
  font: small Helvetica Neue, sans-serif, Droid Sans Fallback;
  background: #dddddd;
  color: black;
  border: outset 0.2em;
}

.dfn-panel * {
  margin: 0;
}

.dfn-panel > b {
  display: block;
}

.dfn-panel ul a[href] {
  color: black;
}

.dfn-panel a:not(:hover) {
  text-decoration: none !important;
  border-bottom: none !important;
}

.dfn-panel a[href]:hover {
  border-bottom-width: 1px;
}

.dfn-panel > b + b {
  margin-top: 0.25em;
}

.dfn-panel ul {
  padding: 0;
}

.dfn-panel li {
  list-style: inside;
}

.dfn-panel.docked {
  display: inline-block;
  position: fixed;
  left: 0.5em;
  top: unset;
  bottom: 2em;
  margin: 0 auto;
  /* 0.75em from padding (x2), 0.5em from left position, 0.2em border (x2) */
  max-width: calc(100vw - 0.75em * 2 - 0.5em - 0.2em * 2);
  max-height: 30vh;
}
</style>
		
		<title>RTC Accessibility User Requirements</title>
		<style id="respec-mainstyle">/*****************************************************************
 * ReSpec specific CSS
 *****************************************************************/
@keyframes pop {
  0% {
    transform: scale(1, 1);
  }
  25% {
    transform: scale(1.25, 1.25);
    opacity: 0.75;
  }
  100% {
    transform: scale(1, 1);
  }
}

/* Override code highlighter background */
.hljs {
  background: transparent !important;
}

/* --- INLINES --- */
h1 abbr,
h2 abbr,
h3 abbr,
h4 abbr,
h5 abbr,
h6 abbr,
a abbr {
  border: none;
}

dfn {
  font-weight: bold;
}

a.internalDFN {
  color: inherit;
  border-bottom: 1px solid #99c;
  text-decoration: none;
}

a.externalDFN {
  color: inherit;
  border-bottom: 1px dotted #ccc;
  text-decoration: none;
}

a.bibref {
  text-decoration: none;
}

.respec-offending-element:target {
  animation: pop 0.25s ease-in-out 0s 1;
}

.respec-offending-element,
a[href].respec-offending-element {
  text-decoration: red wavy underline;
}
@supports not (text-decoration: red wavy underline) {
  .respec-offending-element:not(pre) {
    display: inline-block;
  }
  .respec-offending-element {
    /* Red squiggly line */
    background: url(data:image/gif;base64,R0lGODdhBAADAPEAANv///8AAP///wAAACwAAAAABAADAEACBZQjmIAFADs=)
      bottom repeat-x;
  }
}

#references :target {
  background: #eaf3ff;
  animation: pop 0.4s ease-in-out 0s 1;
}

cite .bibref {
  font-style: normal;
}

code {
  color: #c83500;
}

th code {
  color: inherit;
}

a[href].orcid {
    padding-left: 4px;
    padding-right: 4px;
}

a[href].orcid > svg {
    margin-bottom: -2px;
}

/* --- TOC --- */

.toc a,
.tof a {
  text-decoration: none;
}

a .secno,
a .figno {
  color: #000;
}

ul.tof,
ol.tof {
  list-style: none outside none;
}

.caption {
  margin-top: 0.5em;
  font-style: italic;
}

/* --- TABLE --- */

table.simple {
  border-spacing: 0;
  border-collapse: collapse;
  border-bottom: 3px solid #005a9c;
}

.simple th {
  background: #005a9c;
  color: #fff;
  padding: 3px 5px;
  text-align: left;
}

.simple th a {
  color: #fff;
  padding: 3px 5px;
  text-align: left;
}

.simple th[scope="row"] {
  background: inherit;
  color: inherit;
  border-top: 1px solid #ddd;
}

.simple td {
  padding: 3px 10px;
  border-top: 1px solid #ddd;
}

.simple tr:nth-child(even) {
  background: #f0f6ff;
}

/* --- DL --- */

.section dd > p:first-child {
  margin-top: 0;
}

.section dd > p:last-child {
  margin-bottom: 0;
}

.section dd {
  margin-bottom: 1em;
}

.section dl.attrs dd,
.section dl.eldef dd {
  margin-bottom: 0;
}

#issue-summary > ul,
.respec-dfn-list {
  column-count: 2;
}

#issue-summary li,
.respec-dfn-list li {
  list-style: none;
}

details.respec-tests-details {
  margin-left: 1em;
  display: inline-block;
  vertical-align: top;
}

details.respec-tests-details > * {
  padding-right: 2em;
}

details.respec-tests-details[open] {
  z-index: 999999;
  position: absolute;
  border: thin solid #cad3e2;
  border-radius: 0.3em;
  background-color: white;
  padding-bottom: 0.5em;
}

details.respec-tests-details[open] > summary {
  border-bottom: thin solid #cad3e2;
  padding-left: 1em;
  margin-bottom: 1em;
  line-height: 2em;
}

details.respec-tests-details > ul {
  width: 100%;
  margin-top: -0.3em;
}

details.respec-tests-details > li {
  padding-left: 1em;
}

a[href].self-link:hover {
  opacity: 1;
  text-decoration: none;
  background-color: transparent;
}

h2,
h3,
h4,
h5,
h6 {
  position: relative;
}

aside.example .marker > a.self-link {
  color: inherit;
}

h2 > a.self-link,
h3 > a.self-link,
h4 > a.self-link,
h5 > a.self-link,
h6 > a.self-link {
  border: none;
  color: inherit;
  font-size: 83%;
  height: 2em;
  left: -1.6em;
  opacity: 0.5;
  position: absolute;
  text-align: center;
  text-decoration: none;
  top: 0;
  transition: opacity 0.2s;
  width: 2em;
}

h2 > a.self-link::before,
h3 > a.self-link::before,
h4 > a.self-link::before,
h5 > a.self-link::before,
h6 > a.self-link::before {
  content: "ยง";
  display: block;
}

@media (max-width: 767px) {
  dd {
    margin-left: 0;
  }

  /* Don't position self-link in headings off-screen */
  h2 > a.self-link,
  h3 > a.self-link,
  h4 > a.self-link,
  h5 > a.self-link,
  h6 > a.self-link {
    left: auto;
    top: auto;
  }
}

@media print {
  .removeOnSave {
    display: none;
  }
}
</style>
		
		
	<meta name="description" content="This document outlines various accessibility related user needs, requirements and scenarios for Real-time communication (RTC). These user needs should drive accessibility requirements in various related specifications and the overall architecture that enables it. It first introduces a definition of RTC as used throughout the document, and outlines how RTC accessibility can support the needs of people with disabilities. It defines the term user needs as used throughout the document and then goes on to list a range of these user needs and their related requirements. Following that some quality related scenarios are outlined and finally a data table that maps the user needs contained in this document to related use case requirements found in other technical specifications."><link rel="canonical" href="https://www.w3.org/TR/RAUR/"><style>var {
  position: relative;
  cursor: pointer;
}

var[data-type]::before,
var[data-type]::after {
  position: absolute;
  left: 50%;
  top: -6px;
  opacity: 0;
  transition: opacity 0.4s;
  pointer-events: none;
}

/* the triangle or arrow or caret or whatever */
var[data-type]::before {
  content: "";
  transform: translateX(-50%);
  border-width: 4px 6px 0 6px;
  border-style: solid;
  border-color: transparent;
  border-top-color: #000;
}

/* actual text */
var[data-type]::after {
  content: attr(data-type);
  transform: translateX(-50%) translateY(-100%);
  background: #000;
  text-align: center;
  /* additional styling */
  font-family: "Dank Mono", "Fira Code", monospace;
  font-style: normal;
  padding: 6px;
  border-radius: 3px;
  color: #daca88;
  text-indent: 0;
  font-weight: normal;
}

var[data-type]:hover::after,
var[data-type]:hover::before {
  opacity: 1;
}
</style><script id="initialUserConfig" type="application/json">{
  "trace": true,
  "useExperimentalStyles": true,
  "doRDFa": "1.1",
  "includePermalinks": true,
  "permalinkEdge": true,
  "permalinkHide": false,
  "noRecTrack": true,
  "tocIntroductory": true,
  "specStatus": "ED",
  "diffTool": "http://www.aptest.com/standards/htmldiff/htmldiff.pl",
  "shortName": "RAUR",
  "copyrightStart": "2018",
  "license": "w3c-software-doc",
  "previousPublishDate": "2005-11-23",
  "previousMaturity": "NOTE",
  "edDraftURI": "https://w3c.github.io/apa/rtc/",
  "editors": [
    {
      "name": "Joshue O Connor",
      "mailto": "joconnor@w3.org",
      "url": "https://www.w3.org",
      "company": "W3C",
      "companyURI": "https://www.w3.org",
      "w3cid": 41218
    },
    {
      "name": "Janina Sajka",
      "url": "http://rednote.net/",
      "mailto": "janina@rednote.net",
      "w3cid": 33688
    },
    {
      "name": "Jason White",
      "url": "http://www.ets.org/",
      "mailto": "jjwhite@ets.org",
      "w3cid": 74028
    },
    {
      "name": "Michael Cooper",
      "url": "https://www.w3.org",
      "mailto": "cooper@w3.org",
      "company": "W3C",
      "companyURI": "https://www.w3.org",
      "w3cid": 34017
    }
  ],
  "wg": "Accessible Platform Architectures Working Group",
  "wgURI": "https://www.w3.org/WAI/APA/",
  "wgPublicList": "public-apa",
  "wgPatentURI": "https://www.w3.org/2004/01/pp-impl/83907/status",
  "maxTocLevel": 4,
  "localBiblio": {
    "aicaptcha": {
      "title": "aiCaptcha: Using AI to beat CAPTCHA and post comment spam",
      "date": "",
      "authors": [
        "Casey Chesnut"
      ],
      "editors": [],
      "etAl": false,
      "publisher": "",
      "href": "http://www.brains-n-brawn.com/default.aspx?vDir=aicaptcha"
    },
    "antiphishing": {
      "title": "Phishing Activity Trends Report",
      "date": "July, 2005",
      "authors": [],
      "editors": [],
      "etAl": false,
      "publisher": "Anti-Phishing Working Group",
      "href": "http://antiphishing.org/APWG_Phishing_Activity_Report_Jul_05.pdf"
    },
    "breaking": {
      "title": "Breaking CAPTCHAs Without Using OCR",
      "date": "",
      "authors": [
        "Howard Yeend"
      ],
      "editors": [],
      "etAl": false,
      "publisher": "",
      "href": "http://www.cs.berkeley.edu/%7Emori/gimpy/gimpy.html"
    },
    "breakingocr": {
      "title": "Breaking CAPTCHAs Without Using OCR",
      "date": "",
      "authors": [
        "Howard Yeend"
      ],
      "editors": [],
      "etAl": false,
      "publisher": "",
      "href": "http://www.puremango.co.uk/cm_breaking_captcha_115.php"
    },
    "chafee": {
      "title": "17 USC 121, Limitations on exclusive rights: reproduction for blind or other people with disabilities (also known as the Chafee Amendment)",
      "date": "",
      "authors": [],
      "editors": [],
      "etAl": false,
      "publisher": "",
      "href": "https://www.copyright.gov/title17/92chap1.html"
    },
    "captcha-ocr": {
      "title": "CAPTCHA: Attacks and Weaknesses against OCR technology",
      "date": "2013",
      "authors": [
        "Silky Azad",
        "Kiran Jain"
      ],
      "publisher": "Journal of Computer science and Technology",
      "etAl": false,
      "editors": [],
      "href": "https://computerresearch.org/index.php/computer/article/download/368/368"
    },
    "information-security": {
      "title": "Handbook of Information and Communication Security",
      "authors": [
        "Peter Stavroulakis",
        "Mark Stamp"
      ],
      "publisher": "Springer Science &amp; Business Media",
      "date": "2010"
    },
    "kaPoW-plugins": {
      "title": "kaPoW plugins: protecting web applications using reputation-based proof-of-work",
      "date": "2012",
      "authors": [
        "Tien Le",
        "Akshay Dua",
        "Wu-chang Feng"
      ],
      "editors": [],
      "etAl": false,
      "publisher": "Proceedings of the 2nd Joint WICOW/AIRWeb Workshop on Web Quality",
      "pages": "60-63"
    },
    "killbots": {
      "title": "Botz-4-Sale: Surviving DDos Attacks that Mimic Flash Crowds",
      "date": "",
      "authors": [
        "Srikanth Kandula",
        "Dina Katabi",
        "Matthias Jacob",
        "Arthur Burger"
      ],
      "editors": [],
      "etAl": false,
      "publisher": "",
      "href": "https://www.usenix.org/legacy/events/nsdi05/tech/kandula/kandula_html/"
    },
    "marrakehs": {
      "title": "Marrakesh Treaty to Facilitate Access to Published Works for Persons Who Are Blind, Visually Impaired or Otherwise Print Disabled",
      "authors": [],
      "editors": [],
      "etAl": false,
      "publisher": "World Intellectual Property Organization",
      "date": "27 June 2013",
      "href": "https://www.wipo.int/treaties/en/ip/marrakesh"
    },
    "newscom": {
      "title": "Spam-bot tests flunk the blind",
      "date": "2 July 2003",
      "authors": [
        "Paul Festa"
      ],
      "editors": [],
      "etAl": false,
      "publisher": "News.com",
      "href": "https://web.archive.org/web/20030707210529/http://news.com.com/2100-1032-1022814.html"
    },
    "pinguard": {
      "title": "PIN Guard",
      "date": "",
      "authors": [],
      "editors": [],
      "etAl": false,
      "publisher": "ING Direct site",
      "href": "https://secure1.ingdirect.com/tpw/popup_whatIsThis.html"
    },
    "privacy-pass": {
      "title": "Privacy Pass: Bypassing Internet Challenges Anonymously",
      "date": "2018",
      "authors": [
        "Alex Davidson",
        "Ian Goldberg",
        "Nick Sullivan",
        "George Tankersley",
        "Filippo Valsorda"
      ],
      "editors": [],
      "etAl": false,
      "publisher": "Proceedings on Privacy Enhancing technologies; 2018 (3):164-180",
      "href": "https://www.petsymposium.org/2018/files/papers/issue3/popets-2018-0026.pdf"
    },
    "pwntcha": {
      "title": "PWNtcha - CAPTCHA decoder",
      "date": "",
      "authors": [
        "Sam Hocevar"
      ],
      "editors": [],
      "etAl": false,
      "publisher": "",
      "href": "http://sam.zoy.org/pwntcha/"
    },
    "solving-captchas": {
      "authors": [
        "Elie Bursztein"
      ],
      "etAl": true,
      "editors": [],
      "title": "How good are humans at solving CAPTCHAs? A large scale evaluation",
      "publisher": "2010 IEEE symposium on security and privacy",
      "date": "2010"
    },
    "tls-tracking": {
      "title": "Exploiting TLS Client Authentication for Widespread User Tracking",
      "date": "2018",
      "authors": [
        "Lucas Foppe",
        "Jeremy Martin",
        "Travis Mayberry",
        "Eric C. Rye",
        "Lamont Brown"
      ],
      "publisher": "Proceedings on Privacy Enhancing Technologies",
      "etAl": false,
      "editors": [],
      "href": "https://www.petsymposium.org/2018/files/papers/issue4/popets-2018-0031.pdf"
    },
    "turing": {
      "title": "The Turing Test",
      "date": "2002",
      "authors": [],
      "editors": [],
      "etAl": false,
      "publisher": "he Alan Turing Internet Scrapbook",
      "href": "http://www.turing.org.uk/turing/scrapbook/test.html"
    },
    "eval-audio": {
      "authors": [
        "Bigham, J. P.",
        "Cavender, A. C."
      ],
      "date": "April 2009",
      "title": "Evaluating existing audio CAPTCHAs and an interface optimized for non-visual use",
      "publisher": "In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems"
    },
    "video-events": {
      "authors": [
        "Catuogno, L.",
        "Galdi, C."
      ],
      "date": "2014",
      "title": "On user authentication by means of video events recognition",
      "publisher": "Journal of Ambient Intelligence and Humanized Computing 5(6)",
      "pages": "909-918",
      "doi": "doi:10.1007/s12652-014-0248-5"
    },
    "auth-mult": {
      "authors": [
        "Cetin, C."
      ],
      "date": "2015",
      "title": "Design, Testing and Implementation of a New Authentication Method Using Multiple Devices",
      "publisher": "J. Ligatti, D. Goldgof, & Y. Liu (Eds.): ProQuest Dissertations Publishing"
    },
    "captchastar": {
      "authors": [
        "Conti, M.",
        "Guarisco, C.",
        "Spolaor, R."
      ],
      "date": "2015",
      "title": "CAPTCHaStar! A novel CAPTCHA based on interactive shape discovery"
    },
    "captcha-ld": {
      "authors": [
        "Gafni, R.",
        "Nagar, I."
      ],
      "title": "The Effect of CAPTCHA on User Experience among Users with and without Learning Disabilities"
    },
    "civil-rights-captcha": {
      "authors": [
        "Hernรกndez-Castro, C. J.",
        "Barrero, D. F.",
        "R-Moreno, M. D."
      ],
      "date": "2016",
      "title": "Machine learning and empathy: the Civil Rights CAPTCHA",
      "publisher": "Concurrency and Computation: Practice and Experience, 28(4)",
      "pages": "1310-1323",
      "doi": "doi:10.1002/cpe.3632"
    },
    "iso-8859-1": {
      "title": "Information technology -- 8-bit single-byte coded graphic character sets -- Part 1: Latin alphabet No. 1",
      "href": "https://www.iso.org/standard/28245.html",
      "publisher": "International Organization for Standardization",
      "date": "1998"
    },
    "facecaptcha": {
      "authors": [
        "Kim, J.",
        "Kim, S.",
        "Yang, J.",
        "Ryu, J.-h.",
        "Wohn, K."
      ],
      "date": "2014",
      "title": "FaceCAPTCHA: a CAPTCHA that identifies the gender of face images unrecognized by existing gender classifiers",
      "publisher": "An International Journal, 72(2)",
      "pages": "1215-1237. ",
      "doi": "doi:10.1007/s11042-013-1422-z"
    },
    "video-captcha-security": {
      "authors": [
        "Kluever, K."
      ],
      "date": "2008",
      "title": "Evaluating the usability and security of a video CAPTCHA",
      "publisher": "R. Zanibbi, Z. Butler, & R. Canosa (Eds.): ProQuest Dissertations Publishing."
    },
    "social-classification": {
      "authors": [
        "Korayem, M."
      ],
      "date": "2015",
      "title": "Social and egocentric image classification for scientific and privacy applications",
      "publisher": "D. Crandall, J. Bollen, A. Kapadia, & P. Radivojac (Eds.): ProQuest Dissertations Publishing."
    },
    "facial-captcha-attack": {
      "authors": [
        "Li, Q."
      ],
      "date": "2015",
      "title": "A computer vision attack on the ARTiFACIAL CAPTCHA",
      "publisher": "An International Journal, 74(13)",
      "pages": "4583-4597",
      "doi": "doi:10.1007/s11042-013-1823-z"
    },
    "defeat-line-noise": {
      "authors": [
        "Nakaguro, Y.",
        "Dailey, M. N.",
        "Marukatat, S.",
        "Makhanov, S. S."
      ],
      "date": "2013",
      "title": "Defeating line-noise CAPTCHAs with multiple quadratic snakes",
      "publisher": "Computers & Security, 37",
      "pages": "91-110",
      "doi": "doi:10.1016/j.cose.2013.05.003"
    },
    "3d-captcha-security": {
      "authors": [
        "Nguyen, V. D.",
        "Chow, Y.-W.",
        "Susilo, W."
      ],
      "date": "2014",
      "title": "On the security of text-based 3D CAPTCHAs",
      "publisher": "Computers & Security, 45",
      "pages": "84-99",
      "doi": "doi:10.1016/j.cose.2014.05.004"
    },
    "recaptcha": {
      "title": "reCAPTCHA",
      "publisher": "Google",
      "href": "https://www.google.com/recaptcha/"
    },
    "recaptcha-attacks": {
      "authors": [
        "Sano, S.",
        "Otsuka, T.",
        "Itoyama, K.",
        "Okuno, H. G."
      ],
      "date": "2015",
      "title": "HMM-based Attacks on Google's ReCAPTCHA with Continuous Visual and Audio Symbols",
      "publisher": "Journal of Information Processing, 23(6)",
      "pages": "814-826",
      "doi": "doi:10.2197/ipsjjip.23.814"
    },
    "task-completion": {
      "authors": [
        "Sauer, G.",
        "Lazar, J.",
        "Hochheiser, H.",
        "Feng, J."
      ],
      "date": "2010",
      "title": "Towards a universally usable human interaction proof: evaluation of task completion strategies",
      "publisher": "ACM Transactions on Accessible Computing (TACCESS), 2(4)",
      "pages": "15"
    },
    "captcha-robustness": {
      "authors": [
        "Tangmanee, C."
      ],
      "date": "2016",
      "title": "Effects of Text Rotation, String Length, and Letter Format on Text-based CAPTCHA Robustness",
      "publisher": "Journal of Applied Security Research, 11(3)",
      "pages": "349-361",
      "doi": "doi:10.1080/19361610.2016.1178553"
    },
    "captcha-security": {
      "authors": [
        "Yan, J.",
        "El Ahmad, A. S."
      ],
      "date": "2009",
      "title": "CAPTCHA Security: A Case Study",
      "publisher": "Security & Privacy, IEEE, 7(4)",
      "doi": "doi:10.1109/MSP.2009.84"
    },
    "36-cfr-1194": {
      "title": "36 CFR Appendix C to Part 1194, Functional Performance Criteria and Technical Requirements",
      "href": "https://www.law.cornell.edu/cfr/text/36/appendix-C_to_part_1194",
      "publisher": "Legal Information Institute"
    },
    "en-301-549": {
      "title": "EN 301 549: Accessibility requirements suitable for public procurement of ICT products and services in Europe",
      "publisher": "CEN/CENELEC/ETSI",
      "href": "http://mandate376.standards.eu/standard"
    },
    "mobile-auth": {
      "authors": [
        "Yeh, H. T.",
        "Chen, B. C.",
        "Wu, Y. C."
      ],
      "date": "2013",
      "title": "Mobile user authentication system in cloud environment",
      "publisher": "Security and Communication Networks, 6(9)",
      "pages": "1161-1168",
      "doi": "doi:10.1002/sec.688"
    },
    "game-captcha": {
      "authors": [
        "Yang, T.-I.",
        "Koong, C.-S.",
        "Tseng, C.-C."
      ],
      "date": "2015",
      "title": "Game-based image semantic CAPTCHA on handset devices",
      "publisher": "An International Journal, 74(14)",
      "pages": "5141-5156",
      "doi": "doi:10.1007/s11042-013-1666-7"
    },
    "marrakesh": {
      "date": "27 June 2013",
      "href": "https://www.wipo.int/treaties/en/ip/marrakesh",
      "publisher": "World Intellectual Property Organization",
      "title": "Marrakesh Treaty to Facilitate Access to Published Works for Persons Who Are Blind, Visually Impaired or Otherwise Print Disabled"
    },
    "ietf-rtc": {
      "date": "March 2015",
      "href": "https://tools.ietf.org/html/rfc7478",
      "publisher": "IETF",
      "title": "Web Real-Time Communication Use Cases and Requirements",
      "id": "ietf-rtc"
    },
    "webrtc-use-cases": {
      "date": "11 December 2018",
      "href": "https://www.w3.org/TR/webrtc-nv-use-cases/",
      "publisher": "W3C",
      "title": "WebRTC Next Version Use Cases",
      "id": "webrtc-use-cases"
    },
    "rtt-sip": {
      "date": "June 2008",
      "href": "https://tools.ietf.org/html/rfc5194",
      "publisher": "IETF, Network Working Group",
      "title": "Framework for Real-Time Text over IP Using the Session Initiation Protocol (SIP)",
      "id": "rtt-sip"
    },
    "EN301-549": {
      "date": "August 2018",
      "href": "http://mandate376.standards.eu/standard",
      "publisher": "CEN/CENELEC/ETSI",
      "title": "Accessibility requirements suitable for public procurement of ICT products and services in Europe",
      "id": "en301-549"
    },
    "webrtc-priority": {
      "date": "12 February 2020",
      "href": "https://w3c.github.io/webrtc-priority/",
      "publisher": "W3C",
      "title": "WebRTC DSCP Control API",
      "id": "webrtc-priority"
    },
    "ietf-relay": {
      "date": "August 5, 2019",
      "href": "https://tools.ietf.org/html/draft-rosen-rue-00/",
      "publisher": "IETF",
      "title": "Interoperability Profile for Relay User EquipmentPI",
      "id": "ietf-relay"
    }
  },
  "publishISODate": "2020-02-26T00:00:00.000Z",
  "generatedSubtitle": "Editor's Draft 26 February 2020"
}</script><link rel="stylesheet" href="https://www.w3.org/StyleSheets/TR/2016/W3C-ED"></head>
	<body class="h-entry informative"><div class="head">
      <a class="logo" href="https://www.w3.org/"><img alt="W3C" src="https://www.w3.org/StyleSheets/TR/2016/logos/W3C" width="72" height="48"></a> <h1 id="title" class="title">RTC Accessibility User Requirements</h1>
      
      <h2>
        W3C Editor's Draft
        <time class="dt-published" datetime="2020-02-26">26 February 2020</time>
      </h2>
      <dl>
        <dt>This version:</dt><dd>
                <a class="u-url" href="https://w3c.github.io/apa/rtc/">https://w3c.github.io/apa/rtc/</a>
              </dd><dt>Latest published version:</dt><dd>
                <a href="https://www.w3.org/TR/RAUR/">https://www.w3.org/TR/RAUR/</a>
              </dd>
        <dt>Latest editor's draft:</dt><dd><a href="https://w3c.github.io/apa/rtc/">https://w3c.github.io/apa/rtc/</a></dd>
        
        
        
        
        
        <dt>Editors:</dt>
        <dd class="p-author h-card vcard" data-editor-id="41218"><a class="ed_mailto u-email email p-name" href="mailto:joconnor@w3.org">Joshue O Connor</a>
            (W3C)
          </dd><dd class="p-author h-card vcard" data-editor-id="33688"><a class="ed_mailto u-email email p-name" href="mailto:janina@rednote.net">Janina Sajka</a></dd><dd class="p-author h-card vcard" data-editor-id="74028"><a class="ed_mailto u-email email p-name" href="mailto:jjwhite@ets.org">Jason White</a></dd><dd class="p-author h-card vcard" data-editor-id="34017"><a class="ed_mailto u-email email p-name" href="mailto:cooper@w3.org">Michael Cooper</a>
            (W3C)
          </dd>
        
        
        
      </dl>
      
      
      
      <p class="copyright">
      <a href="https://www.w3.org/Consortium/Legal/ipr-notice#Copyright">Copyright</a>
      ยฉ
      2018-2020
      
      <a href="https://www.w3.org/"><abbr title="World Wide Web Consortium">W3C</abbr></a><sup>ยฎ</sup> (<a href="https://www.csail.mit.edu/"><abbr title="Massachusetts Institute of Technology">MIT</abbr></a>,
      <a href="https://www.ercim.eu/"><abbr title="European Research Consortium for Informatics and Mathematics">ERCIM</abbr></a>, <a href="https://www.keio.ac.jp/">Keio</a>,
      <a href="https://ev.buaa.edu.cn/">Beihang</a>). 
      W3C <a href="https://www.w3.org/Consortium/Legal/ipr-notice#Legal_Disclaimer">liability</a>,
      <a href="https://www.w3.org/Consortium/Legal/ipr-notice#W3C_Trademarks">trademark</a> and <a rel="license" href="https://www.w3.org/Consortium/Legal/2015/copyright-software-and-document">permissive document license</a> rules
      apply.
    </p>
      <hr title="Separator for header">
    </div>
		<section id="abstract" class="introductory">
			<h2>Abstract</h2>
<p>This document outlines various accessibility related user needs, requirements and scenarios for Real-time communication (<abbr title="Real-time communication">RTC</abbr>). These user needs should drive accessibility requirements in various related specifications and the overall architecture that enables it. It first introduces a definition of <abbr title="Real-time communication">RTC</abbr> as used throughout the document, and outlines how <abbr title="Real-time communication">RTC</abbr> accessibility can support the needs of people with disabilities. It defines the term user needs as used throughout the document and then goes on to list a range of these user needs and their related requirements. Following that some quality related scenarios are outlined and finally a data table that maps the user needs contained in this document to related use case requirements found in other technical specifications.</p>

<p>This document is most explicitly not a collection of baseline requirements. It is also important to note that some of the requirements may be implemented at a system or platform level, and some may be authoring requirements.</p>
</section>

	<section id="sotd" class="introductory"><h2>Status of This Document</h2><p><em>This section describes the status of this document at the time of its publication. Other documents may supersede this document. A list of current <abbr title="World Wide Web Consortium">W3C</abbr> publications and the latest revision of this technical report can be found in the <a href="https://www.w3.org/TR/"><abbr title="World Wide Web Consortium">W3C</abbr> technical reports index</a> at https://www.w3.org/TR/.</em></p> <p>
      This document was published by the <a href="https://www.w3.org/WAI/APA/">Accessible Platform Architectures Working Group</a> as an
      Editor's Draft.
      
    </p><p>
      
      Comments regarding this document are welcome.
            Please send them to
            <a href="mailto:public-apa@w3.org">public-apa@w3.org</a>
            (<a href="https://lists.w3.org/Archives/Public/public-apa/">archives</a>).
          
    </p><p>
      Publication as an Editor's Draft does not imply endorsement by the
      <abbr title="World Wide Web Consortium">W3C</abbr> Membership. This is a draft document and may be updated, replaced or
      obsoleted by other documents at any time. It is inappropriate to cite this
      document as other than work in progress.
    </p><p>
      
        This document was produced by a group
        operating under the
        <a href="https://www.w3.org/Consortium/Patent-Policy/"><abbr title="World Wide Web Consortium">W3C</abbr> Patent Policy</a>.
       The group does not expect this document to become a <abbr title="World Wide Web Consortium">W3C</abbr> Recommendation.
      
                  <abbr title="World Wide Web Consortium">W3C</abbr> maintains a
                  <a rel="disclosure" href="https://www.w3.org/2004/01/pp-impl/83907/status">public list of any patent disclosures</a>
            made in connection with the deliverables of
            the group; that page also includes
            instructions for disclosing a patent. An individual who has actual
            knowledge of a patent which the individual believes contains
            <a href="https://www.w3.org/Consortium/Patent-Policy/#def-essential">Essential Claim(s)</a>
            must disclose the information in accordance with
            <a href="https://www.w3.org/Consortium/Patent-Policy/#sec-Disclosure">section 6 of the <abbr title="World Wide Web Consortium">W3C</abbr> Patent Policy</a>.
          
      
    </p><p>
                  This document is governed by the
                  <a id="w3c_process_revision" href="https://www.w3.org/2019/Process-20190301/">1 March 2019 <abbr title="World Wide Web Consortium">W3C</abbr> Process Document</a>.
                </p></section><nav id="toc"><h2 class="introductory" id="table-of-contents">Table of Contents</h2><ol class="toc"><li class="tocline"><a class="tocxref" href="#abstract">Abstract</a></li><li class="tocline"><a class="tocxref" href="#sotd">Status of This Document</a></li><li class="tocline"><a class="tocxref" href="#introduction"><bdi class="secno">1. </bdi>Introduction</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#real-time-communication-and-accessibility"><bdi class="secno">1.1 </bdi>Real-time communication and accessibility </a></li><li class="tocline"><a class="tocxref" href="#user-needs-definition"><bdi class="secno">1.2 </bdi>User needs definition</a></li></ol></li><li class="tocline"><a class="tocxref" href="#user-needs-and-requirements"><bdi class="secno">2. </bdi>User needs and requirements</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#incoming-calls-and-caller-id"><bdi class="secno">2.1 </bdi>Incoming calls and caller ID</a></li><li class="tocline"><a class="tocxref" href="#routing-and-communication-channel-control"><bdi class="secno">2.2 </bdi>Routing and communication channel control</a></li><li class="tocline"><a class="tocxref" href="#dynamic-audio-description-values-in-live-conferencing"><bdi class="secno">2.3 </bdi>Dynamic audio description values in live conferencing</a></li><li class="tocline"><a class="tocxref" href="#quality-synchronisation-and-playback"><bdi class="secno">2.4 </bdi>Quality synchronisation and playback</a></li><li class="tocline"><a class="tocxref" href="#simultaneous-voice-text-signing"><bdi class="secno">2.5 </bdi>Simultaneous voice, text &amp; signing</a></li><li class="tocline"><a class="tocxref" href="#emergency-calls-support-for-real-time-text-rtt"><bdi class="secno">2.6 </bdi>Emergency calls: Support for Real-time text (<abbr title="Real-time Text">RTT</abbr>) </a></li><li class="tocline"><a class="tocxref" href="#video-relay-services-and-vrs-and-remote-interpretation-vri"><bdi class="secno">2.7 </bdi>Video relay services and (<abbr title="Video Relay Services">VRS</abbr>) and remote interpretation (<abbr title="Remote Interpretation">VRI</abbr>)</a></li><li class="tocline"><a class="tocxref" href="#distinguishing-sent-and-received-text-with-rtt"><bdi class="secno">2.8 </bdi>Distinguishing sent and received text with <abbr title="Real-time Text">RTT</abbr></a></li><li class="tocline"><a class="tocxref" href="#call-participants-and-status"><bdi class="secno">2.9 </bdi>Call participants and status</a></li><li class="tocline"><a class="tocxref" href="#live-transcription-and-captioning-support"><bdi class="secno">2.10 </bdi>Live transcription and captioning support</a></li><li class="tocline"><a class="tocxref" href="#assistance-for-users-with-cognitive-disabilities"><bdi class="secno">2.11 </bdi>Assistance for users with cognitive disabilities</a></li><li class="tocline"><a class="tocxref" href="#personalized-symbol-sets-for-users-with-cognitive-disabilities"><bdi class="secno">2.12 </bdi>Personalized symbol sets for users with cognitive disabilities</a></li><li class="tocline"><a class="tocxref" href="#internet-relay-chat-irc-style-interfaces-required-by-blind-users"><bdi class="secno">2.13 </bdi>Internet relay chat (<abbr title="Internet Relay Chat">IRC</abbr>) style interfaces required by blind users</a></li><li class="tocline"><a class="tocxref" href="#deaf-users-video-resolution-and-frame-rates"><bdi class="secno">2.14 </bdi>Deaf users: Video resolution and frame rates</a></li></ol></li><li class="tocline"><a class="tocxref" href="#quality-of-service-scenarios"><bdi class="secno">3. </bdi>Quality of service scenarios</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#bandwidth-for-audio"><bdi class="secno">3.1 </bdi>Bandwidth for audio </a></li><li class="tocline"><a class="tocxref" href="#bandwidth-for-video"><bdi class="secno">3.2 </bdi>Bandwidth for video </a></li></ol></li><li class="tocline"><a class="tocxref" href="#data-table-mapping-user-needs-with-related-specifications"><bdi class="secno">4. </bdi>Data table mapping user needs with related specifications</a></li><li class="tocline"><a class="tocxref" href="#acknowledgments"><bdi class="secno">A. </bdi>Acknowledgments</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#participants-of-the-apa-working-group-active-in-the-development-of-this-document"><bdi class="secno">A.1 </bdi> Participants of the <abbr title="Accessible Platforms Architecure Working Group">APA</abbr> working group active in the development of this document:</a></li><li class="tocline"><a class="tocxref" href="#enabling-funders"><bdi class="secno">A.2 </bdi>Enabling funders<span class="formerLink" aria-label="ยง"></span></a></li></ol></li><li class="tocline"><a class="tocxref" href="#references"><bdi class="secno">B. </bdi>References</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#informative-references"><bdi class="secno">B.1 </bdi>Informative references</a></li></ol></li></ol></nav>
		<section id="introduction">
			<h2 id="x1-introduction"><bdi class="secno">1. </bdi>Introduction<a class="self-link" aria-label="ยง" href="#introduction"></a></h2>

			                

		<h3 id="what-is-real-time-communication-rtc"> What is Real-time communication (<abbr title="Real-time communication">RTC</abbr>)? <a class="self-link" aria-label="ยง" href="#introduction"></a></h3>
<p>The traditional data exchange model is client to server. Real-time communication (<abbr title="Real-time communication">RTC</abbr>) is game-changing. It is enabled in part, by specifications like <abbr title="Web Real-time communication">WebRTC</abbr> as this provides real-time peer to peer Audio, Video and Data exchange directly between supported web browsers without the need for browser plugins, as well as fast applications for video/audio calls, text chat, file exchange, screen sharing and gaming. However, <abbr title="Web Real-time communication">WebRTC</abbr> is not the sole specification with responsibility to enable accessible real-time communications, as use cases and requirements are broad - as outlined in the <abbr title="Internet Engineering Task Force">IETF</abbr> RFC 7478 'Web Real-Time Communication Use Cases and Requirements' document. [<cite><a class="bibref" data-link-type="biblio" href="#bib-ietf-rtc" title="Web Real-Time Communication Use Cases and Requirements">ietf-rtc</a></cite>]</p>

<p>Accessible <abbr title="Real-time communication">RTC</abbr> is enabled by a combination of technologies and specifications such as those from the Media Working Group, Web and Networks IG, Second Screen, and Web Audio Working group as well as <abbr title="Accessibility Guidelines Working Group">AGWG</abbr> and <abbr title="Accessible Rich Internet Applications">ARIA</abbr>. <abbr title="Accessible Platforms Architecure Working Group">APA</abbr> hopes this work will inform how these groups meet various responsibilities for enabling <abbr title="Real-time communication">RTC</abbr>, as well updating use cases in various groups. For example, you can view current work on <abbr title="Web Real-time communication">WebRTC</abbr> Next Version Use Cases First Public Working Draft.[<cite><a class="bibref" data-link-type="biblio" href="#bib-webrtc-use-cases" title="WebRTC Next Version Use Cases">webrtc-use-cases</a></cite>]</p>


<section id="real-time-communication-and-accessibility">

<h3 id="x1-1-real-time-communication-and-accessibility"><bdi class="secno">1.1 </bdi>Real-time communication and accessibility <a class="self-link" aria-label="ยง" href="#real-time-communication-and-accessibility"></a></h3>
<p><abbr title="Real-time communication">RTC</abbr> has the potential to allow improved accessibility features that will support a broad range of user needs for people with a wide range of disabilities. These needs can be met through improved audio and video quality, audio routing, captioning, improved live transcription, transfer of alternate formats such as sign-language, text-messaging / chat, real time user support, status polling.</p>
		</section>


		<section id="user-needs-definition">
<h3 id="x1-2-user-needs-definition"><bdi class="secno">1.2 </bdi>User needs definition<a class="self-link" aria-label="ยง" href="#user-needs-definition"></a></h3>
<p>This document outlines various accessibility related user needs for Accessible <abbr title="Real-time communication">RTC</abbr>. These user needs should drive accessibility requirements for Accessible <abbr title="Real-time communication">RTC</abbr> and its related architecture. These  come from people with disabilities who use assistive technology (AT) and wish to see the features described available within Accessible <abbr title="Real-time communication">RTC</abbr> enabled applications.</p>

<p>User needs are presented with related requirements and also some in a range of scenarios; (which can be thought of as similar to User stories). User needs and requirements are being actively reviewing by <abbr title="Research Questions Task Force">RQTF</abbr>/<abbr title="Accessible Platforms Architecure Working Group">APA</abbr> in the context of the broader scope and application of the contents of this document.</p>
		</section>

</section>


<section id="user-needs-and-requirements">
<h2 id="x2-user-needs-and-requirements"><bdi class="secno">2. </bdi>User needs and requirements<a class="self-link" aria-label="ยง" href="#user-needs-and-requirements"></a></h2>
<p>The following outlines a range of user needs and requirements. The user needs below have also been compared to existing use cases for Real-Time Text (<abbr title="Real-time Text">RTT</abbr>) such as the <abbr title="Internet Engineering Task Force">IETF</abbr> Framework for Real-Time Text over IP Using the <abbr title="Internet Engineering Task Force">IETF</abbr> Session Initiation Protocol RFC 5194 and the European Procurement Standard EN 301 549. [<cite><a class="bibref" data-link-type="biblio" href="#bib-rtt-sip" title="Framework for Real-Time Text over IP Using the Session Initiation Protocol (SIP)">rtt-sip</a></cite>] [<cite><a class="bibref" data-link-type="biblio" href="#bib-en301-549" title="Accessibility requirements suitable for public procurement of ICT products and services in Europe">EN301-549</a></cite>]</p>


		<section id="incoming-calls-and-caller-id">
<h3 id="x2-1-incoming-calls-and-caller-id"><bdi class="secno">2.1 </bdi>Incoming calls and caller ID<a class="self-link" aria-label="ยง" href="#incoming-calls-and-caller-id"></a></h3>
<ul>
<li><strong>User Need 1:</strong> A screen-reader user or user with a cognitive impairment needs to know a call is incoming and needs to recognise the ID of a caller. </li>

<li><strong>REQ 1a:</strong> Provide in an unobtrusive way e.g. a symbol set or other browser notification to indicate incoming calls.</li> 
<li><strong>REQ 1b:</strong> Alert assistive technologies via relevant APIs.</li>

</ul> 
</section>

<section id="routing-and-communication-channel-control">
		<h3 id="x2-2-routing-and-communication-channel-control"><bdi class="secno">2.2 </bdi>Routing and communication channel control<a class="self-link" aria-label="ยง" href="#routing-and-communication-channel-control"></a></h3>
<ul>
<li><strong>User Need 2:</strong> A blind user of both screen reader and Braille output devices may need to manage audio and text output differently e.g. A user may wish to route notifications to a separate Braille device while continuing the call on a regular Bluetooth headphone once they have accepted it.</li>
<li><strong>REQ 2a:</strong> Provide or support range of browser level audio output and routing options.</li> 
<li><strong>REQ 2b:</strong> Allow direct system output, such as alerts or other output to a different device other than the screen reader, such as a Braille output device or other hardware.</li>
</ul>

<ul>
<li><strong>User Need 3:</strong> A deaf user needs to move parts of a live teleconference session (as separate streams) to one or more devices for greater control.</li>

<li><strong>REQ 3a:</strong> Allow the separate routing of video streams, such as a sign language interpreter to a separate high resolution display.</li>

</ul>


<ul>
<li><strong>User Need 4:</strong> Users with cognitive disabilities or blind users may have relative volume levels set as preferences which relate to importance, urgency or meaning.</li>

<li><strong>REQ 4a:</strong> Allow the panning or setting of relative levels of audio outputs. </li>
<li><strong>REQ 4b:</strong> Support multichannel audio in the browser. </li>
</ul>

</section>

		<section id="dynamic-audio-description-values-in-live-conferencing">
<h3 id="x2-3-dynamic-audio-description-values-in-live-conferencing"><bdi class="secno">2.3 </bdi>Dynamic audio description values in live conferencing<a class="self-link" aria-label="ยง" href="#dynamic-audio-description-values-in-live-conferencing"></a></h3> 

<ul>
<li><strong>User Need 5:</strong> A user may struggle to hear audio description in a live teleconferencing situation.</li>
 <li><strong>REQ 5a:</strong> Ensure Audio Description (AD) recommended sound values are dynamic.</li>
</ul>
		</section>

		<section id="quality-synchronisation-and-playback">

<h3 id="x2-4-quality-synchronisation-and-playback"><bdi class="secno">2.4 </bdi>Quality synchronisation and playback<a class="self-link" aria-label="ยง" href="#quality-synchronisation-and-playback"></a></h3>

<ul>
<li><strong>User Need 6:</strong> Any deaf or hard of hearing user watching captioning or audio description needs to be confident they are synchronised and accurate. 

</li><li><strong>REQ 6a:</strong> Ensure that any outages or loss to captions or audio description will be repaired while preserving context and meaning. </li>
<li><strong>REQ 6b:</strong> Ensure that the integrity of related alternate supporting tracks or streams - such as transcription, are also in sync with any repairs.</li>
</ul>
		</section>

		<section id="simultaneous-voice-text-signing">
<h3 id="x2-5-simultaneous-voice-text-signing"><bdi class="secno">2.5 </bdi>Simultaneous voice, text &amp; signing<a class="self-link" aria-label="ยง" href="#simultaneous-voice-text-signing"></a></h3>

<ul>
<li><strong>User Need 7:</strong> A deaf user needs to both talk on a call, send and receive instant messages via a text interface and watch sign language using a video stream.</li>

<li><strong>REQ 7a:</strong> Ensure support for multiple simultaneous streams. </li>

</ul>

<strong>NOTE:</strong> This could be partially enabled via <abbr title="Real-time Text">RTT</abbr> in <abbr title="Web Real-time communication">WebRTC</abbr>.

		</section>

		<section id="emergency-calls-support-for-real-time-text-rtt">

<h3 id="x2-6-emergency-calls-support-for-real-time-text-rtt"><bdi class="secno">2.6 </bdi>Emergency calls: Support for Real-time text (<abbr title="Real-time Text">RTT</abbr>) <a class="self-link" aria-label="ยง" href="#emergency-calls-support-for-real-time-text-rtt"></a></h3>

<ul>
<li><strong>User Need 8:</strong> In an emergency situation a deaf, speech impaired, hard of hearing or deaf blind user needs to make an emergency call, instantly send and receive related text messages and or sign via a video stream.</li>

<li><strong>REQ 8a:</strong> Provide or ensure support for <abbr title="Real-time Text">RTT</abbr> in <abbr title="Web Real-time communication">WebRTC</abbr>. 

		</li></ul></section>

		<section id="video-relay-services-and-vrs-and-remote-interpretation-vri">

<h3 id="x2-7-video-relay-services-and-vrs-and-remote-interpretation-vri"><bdi class="secno">2.7 </bdi>Video relay services and (<abbr title="Video Relay Services">VRS</abbr>) and remote interpretation (<abbr title="Remote Interpretation">VRI</abbr>)<a class="self-link" aria-label="ยง" href="#video-relay-services-and-vrs-and-remote-interpretation-vri"></a></h3>

<ul>
<li><strong>User Need 9:</strong> A deaf, speech impaired, or hard of hearing user needs to communicate on a call using a remote video interpretation service to access sign language and interpreter services.</li>

<li><strong>REQ 9a:</strong> Provide or ensure support for <abbr title="Video Relay Services">VRS</abbr>) and Remote Interpretation (<abbr title="Remote Interpretation">VRI</abbr>. For example, this user need may relate to interoperability with third-party services;  <abbr title="Internet Engineering Task Force">IETF</abbr> has looked at standardizing a way to use SIP with <abbr title="Video Relay Services">VRS</abbr> services. [<cite><a class="bibref" data-link-type="biblio" href="#bib-ietf-relay" title="Interoperability Profile for Relay User EquipmentPI">ietf-relay</a></cite>] <abbr title="Video Relay Services">VRS</abbr> calls may be made between ASL users and hearing persons speaking either English or Spanish.</li>
</ul>
</section>

		<section id="distinguishing-sent-and-received-text-with-rtt">

<h3 id="x2-8-distinguishing-sent-and-received-text-with-rtt"><bdi class="secno">2.8 </bdi>Distinguishing sent and received text with <abbr title="Real-time Text">RTT</abbr><a class="self-link" aria-label="ยง" href="#distinguishing-sent-and-received-text-with-rtt"></a></h3>
<ul>
<li><strong>User Need 10:</strong> A deaf or deaf blind user needs to be to tell the difference between incoming text and outgoing text.
</li><li><strong>REQ 10a:</strong> Ensure when used with <abbr title="Real-time Text">RTT</abbr> functionality, <abbr title="Web Real-time communication">WebRTC</abbr> handles the routing of this information to a format or output of the users choosing.<p></p>
		</li></ul></section>
	
		<section id="call-participants-and-status">
<h3 id="x2-9-call-participants-and-status"><bdi class="secno">2.9 </bdi>Call participants and status<a class="self-link" aria-label="ยง" href="#call-participants-and-status"></a></h3> 
<ul>
<li><strong>User Need 11: </strong> In a teleconference a blind screen-reader user needs to know what participants are on the call, as well as their status (Muted, Talking etc).</li>
<li><strong>REQ 11a:</strong> Ensure participant details such as name and status, whether muted or talking, is accessible to users of Assistive Technologies.</li>
</ul>
		</section>

		<section id="live-transcription-and-captioning-support">

<h3 id="x2-10-live-transcription-and-captioning-support"><bdi class="secno">2.10 </bdi>Live transcription and captioning support<a class="self-link" aria-label="ยง" href="#live-transcription-and-captioning-support"></a></h3>
<ul>
<li><strong>User Need 12:</strong> A deaf user or user with a cognitive disability needs to access a channel containing live transcriptions or captioning during a conference call or broadcast.</li>
 <li><strong>REQ 12a:</strong> Provide support for and honor user preferences of Live Transcription and Captioning such as signed or a related symbol set.</li>

		</ul></section>

		<section id="assistance-for-users-with-cognitive-disabilities">

<h3 id="x2-11-assistance-for-users-with-cognitive-disabilities"><bdi class="secno">2.11 </bdi>Assistance for users with cognitive disabilities<a class="self-link" aria-label="ยง" href="#assistance-for-users-with-cognitive-disabilities"></a></h3>
<ul>
<li><strong>User Need 13: </strong> Users with cognitive disabilities may need assistance when using audio or video communication. </li>
 <li><strong>REQ 13a:</strong> Ensure a <abbr title="Web Real-time communication">WebRTC</abbr> video call could host a technical or user support channel.</li>
  <li><strong>REQ 13b:</strong> Provide support that is customised to the needs of the user.</li>
</ul>

		</section>

		<section id="personalized-symbol-sets-for-users-with-cognitive-disabilities">

<h3 id="x2-12-personalized-symbol-sets-for-users-with-cognitive-disabilities"><bdi class="secno">2.12 </bdi>Personalized symbol sets for users with cognitive disabilities<a class="self-link" aria-label="ยง" href="#personalized-symbol-sets-for-users-with-cognitive-disabilities"></a></h3>

<ul>
<li><strong>User Need 14: </strong> Users with cognitive disabilities may need to use symbol sets for identifying functions available in a <abbr title="Web Real-time communication">WebRTC</abbr> enabled client whether for Voice, File or Data transfer.<p></p>

  </li><li><strong>REQ 14a:</strong> Providing personalization support ensuring that symbols sets are supported as replacements for existing user interface rendering of current functions or controls.</li>
</ul>


</section>

<section id="internet-relay-chat-irc-style-interfaces-required-by-blind-users">

	<h3 id="x2-13-internet-relay-chat-irc-style-interfaces-required-by-blind-users"><bdi class="secno">2.13 </bdi>Internet relay chat (<abbr title="Internet Relay Chat">IRC</abbr>) style interfaces required by blind users<a class="self-link" aria-label="ยง" href="#internet-relay-chat-irc-style-interfaces-required-by-blind-users"></a></h3>
		

<ul>
<li><strong>User Need 15: </strong> A blind screen reader user depending on text to speech (<abbr title="Text to Speech">TTS</abbr>) to interact with their computers and smart devices, requires the traditional Internet Relay Chat (<abbr title="Internet Relay Chat">IRC</abbr>) style interface for <abbr title="Text to Speech">TTS</abbr> to translate text interactions into comprehensible speech.</li>

	  <li><strong>REQ 15a:</strong> Preserve <abbr title="Internet Relay Chat">IRC</abbr> as a configuration option in agents that implement <abbr title="Web Real-time communication">WebRTC</abbr> as opposed to having only the Real-time Text (<abbr title="Real-time Text">RTT</abbr>) type interface favoured by users who are deaf or hearing impaired.  For screen reader users, <abbr title="Text to Speech">TTS</abbr> cannot reasonably translate text into comprehensible speech unless the characters to be pronounced are transmitted in close timing to one another. Typical gaps will result in stuttering and highly unintelligible utterances from the <abbr title="Text to Speech">TTS</abbr> engine.<p></p>



<h4 id="braille-users-and-rtt">Braille users and <abbr title="Real-time Text">RTT</abbr><a class="self-link" aria-label="ยง" href="#braille-users-and-rtt"></a></h4>

<p>Some braille users will also prefer the <abbr title="Real-time Text">RTT</abbr> model. However, braille users desiring text displayed with standard contracted braille might better be served in the manner users relying on Text to Speech (<abbr title="Text to Speech">TTS</abbr>) engines are served, by buffering the data to be transmitted until an end of line character is reached.</p>

		</li></ul></section>

		<section id="deaf-users-video-resolution-and-frame-rates">
<h3 id="x2-14-deaf-users-video-resolution-and-frame-rates"><bdi class="secno">2.14 </bdi>Deaf users: Video resolution and frame rates<a class="self-link" aria-label="ยง" href="#deaf-users-video-resolution-and-frame-rates"></a></h3>

<ul>
<li><strong>User Need 15: </strong> A deaf user watching a signed broadcast needs a high-quality frame rate to maintain legibility and clarity in order to understand what is being signed.

<p><strong>NOTE:</strong> EN 301 549 Section 6,  recommends  <abbr title="Web Real-time communication">WebRTC</abbr> applications should support a frame rate of at least 20 frames per second (FPS). More details can be found at <a href="https://www.etsi.org/deliver/etsi_en/301500_301599/301549/02.01.02_60/en_301549v020102p.pdf"> Accessible Procurement standard for ICT products and services EN 301 549 (PDF)</a></p>

		</li></ul></section>

</section>

		
<section id="quality-of-service-scenarios">

	<h2 id="x3-quality-of-service-scenarios"><bdi class="secno">3. </bdi>Quality of service scenarios<a class="self-link" aria-label="ยง" href="#quality-of-service-scenarios"></a></h2>



<section id="bandwidth-for-audio">
	<h3 id="x3-1-bandwidth-for-audio"><bdi class="secno">3.1 </bdi>Bandwidth for audio <a class="self-link" aria-label="ยง" href="#bandwidth-for-audio"></a></h3>

<p><strong>Scenario:</strong> A hard of hearing user needs better stereo sound so they can have a quality experience in work calls or meetings with friends or family. Transmission aspects, such as decibel range for audio needs to be of high-quality. Industry allows higher audio resolution, but still mostly audio in mono only. </p>

</section>

<section id="bandwidth-for-video">

<h3 id="x3-2-bandwidth-for-video"><bdi class="secno">3.2 </bdi>Bandwidth for video <a class="self-link" aria-label="ยง" href="#bandwidth-for-video"></a></h3>

<p><strong>Scenario:</strong> A hard of hearing user needs better stereo sound so they can have a quality experience in watching HD video or having HD meeting with friends or family. Transmission aspects, such as frames per minute for video quality needs to be of high-quality.</p>

<p><strong>NOTE:</strong> EN 301 549 Section 6,  recommends for <abbr title="Web Real-time communication">WebRTC</abbr> enabled conferencing and communication the application shall be able to encode and decode communication with a frequency range with an upper limit of at least 7KHz. More details can be found at <a href="https://www.etsi.org/deliver/etsi_en/301500_301599/301549/02.01.02_60/en_301549v020102p.pdf"> Accessible Procurement standard for ICT products and services EN 301 549 (PDF)</a></p>

<p><strong>NOTE:</strong> <abbr title="Web Real-time communication">WebRTC</abbr> lets applications prioritise bandwidth dedicated to audio / video / data streams; there is also some experimental work in signalling these needs to the network layer as well as support for prioritising frame rate over resolution in case of congestion. [<cite><a class="bibref" data-link-type="biblio" href="#bib-webrtc-priority" title="WebRTC DSCP Control API">webrtc-priority</a></cite>]</p>

</section>



</section>

<section id="data-table-mapping-user-needs-with-related-specifications">

<h2 id="x4-data-table-mapping-user-needs-with-related-specifications"><bdi class="secno">4. </bdi>Data table mapping user needs with related specifications<a class="self-link" aria-label="ยง" href="#data-table-mapping-user-needs-with-related-specifications"></a></h2>

<p>The following table maps the user needs and requirements presented in this document with other related specifications such as those defined in RFC 5194 - Framework for Real-Time Text over IP Using SIP and EN 301 549 - the EU Procurement Standard. [<cite><a class="bibref" data-link-type="biblio" href="#bib-rtt-sip" title="Framework for Real-Time Text over IP Using the Session Initiation Protocol (SIP)">rtt-sip</a></cite>] [<cite><a class="bibref" data-link-type="biblio" href="#bib-en301-549" title="Accessibility requirements suitable for public procurement of ICT products and services in Europe">EN301-549</a></cite>]</p>

<table>
<caption>Overview of what specifications may address some of the use cases outlined above</caption>
<tbody><tr>
<td></td>
<th scope="col">Related specs or groups</th>
<th scope="col">Mapping to RFC 5194 - Framework for Real-time Text over IP Using SIP:</th>
<th scope="col">Mapping to EN 301 549 - EU procurement standard</th>
</tr>
<tr>
<th scope="row">Incoming calls</th>
<td><abbr title="Web Content Accessibility Guidelines">WCAG</abbr>/<abbr title="Accessibility Guidelines Working Group">AGWG</abbr>, <abbr title="Accessible Rich Internet Applications">ARIA</abbr>.</td>
<td>Similar to 6.2.4.2 Alerting - RFC 5194/ pre-session set up with <abbr title="Real-time Text">RTT</abbr> 6.2.1</td>
<td>Maps to <a href="http://mandate376.standards.eu/standard/technical-requirements/programmatically-determinable-send-and-receive-direction"> 6.2.2.2: Programmatically determinable send and receive direction</a></td>
</tr>

<tr>
<th scope="row">Accessible call setup</th>
<td><abbr title="Web Content Accessibility Guidelines">WCAG</abbr>/<abbr title="Accessibility Guidelines Working Group">AGWG</abbr>, <abbr title="Accessible Rich Internet Applications">ARIA</abbr>.</td>
<td>Under 'General Requirements for ToIP'</td>
<td>No Mapping</td>
</tr>
<tr>
<th scope="row">Routing</th>
<td>
Media Working Group, Web and Networks IG, Second Screen. Audio Device Client Proposal may fulfil this need and allow complex routing and management of multiple audio input and output devices.</td>
<td>No Mapping</td>
<td>No Mapping</td>
</tr>
<tr>
<th scope="row">Dynamic audio description values</th>
<td>
Media Working Group, Web and Networks IG, Second Screen.</td>
<td>No Mapping</td>
<td>No Mapping</td>
</tr>
<tr>
<th scope="row">Audio-subtitling/spoken subtitles</th>
<td>
Media Working Group, Web and Networks IG, Second Screen.</td>
<td>No Mapping</td>
<td>No Mapping</td>
</tr>
<tr>
<th scope="row">Communications control</th>
<td>
Media Working Group, Web and Networks IG. Second Screen API may fulfil this user need. Needs confirmation. HTML5 supports this, the streams need to be separable. Looks like an application implementation and not just a <abbr title="Web Real-time communication">WebRTC</abbr> issue. Could be managed via something like a status bar.</td>
<td>Similar to R26 in 5.2.4. Presentation and User Requirements.</td>
<td>Maps to <a href="http://mandate376.standards.eu/standard/technical-requirements/concurrent-voice-and-text"> 6.2.1.2: Concurrent voice and text</a></td>
</tr>
<tr>
<th scope="row">Text communication data channel</th>
<td>
Media Working Group</td>
	<td> Similar to R26 in RFC 5194 5.2.4. Presentation and User Requirements. NOTE: Very similar user requirement to 'Audio Routing and Communication channel control'</td>
	<td>No Mapping</td>
</tr>
<tr>
<th scope="row">Control relative volume and panning position for multiple audio</th>
<td>
Web Audio Working Group. Multichannel may be mostly covered in the Web Audio group space with some <abbr title="Web Real-time communication">WebRTC</abbr> requirements, and also by the Audio Device Proposal.</td>
<td>No Mapping</td>
<td>Maps to <a href="http://mandate376.standards.eu/standard/technical-requirements/concurrent-voice-and-text">6.2.1.2: Concurrent voice and text</a>  NOTE: Very similar user requirement to 'Audio Routing and Communication channel control'</td>

</tr>
<tr>
<th scope="row">Support for Real-time Text </th>
<td>
<abbr title="Web Real-time communication">WebRTC</abbr></td>
<td>Similar to R26 in RFC 5194 5.2.4. Presentation and User Requirements. NOTE: Very similar user requirement to 'Audio Routing and Communication channel control'</td>
<td>No Mapping</td>
</tr>
<tr>
<th scope="row">Simultaneous voice, text &amp; signing</th>
<td>Could be partially enabled via <abbr title="Real-time Text">RTT</abbr> in <abbr title="Web Real-time communication">WebRTC</abbr>.</td>
<td>
Relates to RFC 5194 - under R2-R8</td>
<td>No Mapping</td>
</tr>
<tr>
<th scope="row">Support for video relay services and (<abbr title="Video Relay Services">VRS</abbr>) and remote interpretation (<abbr title="Remote Interpretation">VRI</abbr>)</th>
<td>May relate to interoperability with third-party services.</td>
<td>
Relates to RFC 5194 - under R21-R23</td>
<td>No Mapping</td>
</tr>
<tr>
<th scope="row">Distinguishing sent and received text</th>
<td>May relate to interoperability with third-party services. This is not <abbr title="Web Real-time communication">WebRTC</abbr> specific and may be just an accessible UI issue.</td>
<td>
Relates to RFC 5194 - under R16 - but this does NOT fully address our use case requirement.</td>
<td>Maps to <a href="http://mandate376.standards.eu/standard/technical-requirements/visually-distinguishable-display"> 6.2.2.1: Visually distinguishable display</a></td>
</tr>
<tr>
<th scope="row">Warning and recovery of lost data</th>
<td>This is not <abbr title="Web Real-time communication">WebRTC</abbr> specific and may be just an accessible UI issue.</td>
<td>
Relates to RFC 5194 - under R14-R15</td>
<td>No Mapping</td>
</tr>
<tr>
<th scope="row">Quality of video resolution and frame rate</th>
<td>No Mapping</td>
<td>No Mapping</td>
<td>EN 301 549 Section 6, recommends <abbr title="Web Real-time communication">WebRTC</abbr> applications should support a frame rate of at least 20 frames per second</td>
</tr>
<tr>
<th scope="row">Assistance for older users or users with cognitive disabilities</th>
<td>Needs clarification/review by <abbr title="Cognitive Accessibility Task Force">COGA</abbr>, may be an accessible UI, or personalisation issue.</td>
<td>
Relates to RFC 5149 - Transport Requirements/ToIP and Relay Services. [To what degree? Are there specific requirements missing that we need to cover?]</td>
<td>No Mapping</td>
</tr>
<tr>
<th scope="row">Identify caller</th>
<td> <abbr title="Web Content Accessibility Guidelines">WCAG</abbr>/<abbr title="Accessibility Guidelines Working Group">AGWG</abbr>, <abbr title="Accessible Rich Internet Applications">ARIA</abbr>. This may a candidate for removal, as identity may be handled by the browser via <a href="https://w3c.github.io/webrtc</abbr>-identity/identity.html">Identity for <abbr title="Web Real-time communication">WebRTC</abbr> 1.0</a>. We may need to co-ordinate with another group that manages identity mechanisms in the browser, if doing so supports our overall use case.</td>
<td>
Similar to R27 in RFC 5194 5.2.4. Presentation and User Requirements</td>
<td>Maps to <a href="http://mandate376.standards.eu/standard/technical-requirements/caller-id">6.3 Caller ID</a></td>
</tr>
<tr>
<th scope="row">Live transcription and captioning</th>
<td>Browser APIs needed to implement this are available; but needs better integration with third-party services (e.g. for sign language translation). Possibly covered by general requirements for ToIP contained in RFC 5194.</td>
<td>
Covered under 5.2.3 (transcoding service requirements). Referring to relay services that provide conversion from speech to text, or text to speech, to enable communication.</td>
<td>No Mapping</td>
</tr>

</tbody></table>
</section>


	<section class="appendix" id="acknowledgments">
			<h2 id="a-acknowledgments"><bdi class="secno">A. </bdi>Acknowledgments<a class="self-link" aria-label="ยง" href="#acknowledgments"></a></h2>
			<section id="participants-of-the-apa-working-group-active-in-the-development-of-this-document">
				<h3 id="a-1-participants-of-the-apa-working-group-active-in-the-development-of-this-document"><bdi class="secno">A.1 </bdi> Participants of the <abbr title="Accessible Platforms Architecure Working Group">APA</abbr> working group active in the development of this document:<a class="self-link" aria-label="ยง" href="#participants-of-the-apa-working-group-active-in-the-development-of-this-document"></a></h3>
				<ul>
					<li>Judy Brewer, <abbr title="World Wide Web Consortium">W3C</abbr></li>
					<li>Michael Cooper, <abbr title="World Wide Web Consortium">W3C</abbr></li>
					<li>Dominique Hazael-Massieux, <abbr title="World Wide Web Consortium">W3C</abbr></li>
					<li>Scott Hollier, Edith Cowan University &amp; Centre For Accessibility </li>
					<li>Steve Lee, <abbr title="World Wide Web Consortium">W3C</abbr></li>
					<li>Stephen Noble, Pearson Plc</li>
					<li>Estella Oncins Noguer, TransMedia UAB</li>
					<li>Joshue O Connor, <abbr title="World Wide Web Consortium">W3C</abbr></li>
					<li>Janina Sajka, Invited Expert</li>
					<li>Jason White, Educational Testing Service</li>
				</ul>

</section>
<section id="enabling-funders">
<h3 id="a-2-enabling-funders"><bdi class="secno">A.2 </bdi>Enabling funders<a class="self-link" aria-label="ยง" href="#enabling-funders"></a><a class="self-link" aria-label="ยง" href="#enabling-funders"></a></h3>
<p>This work is supported by the <a href="https://www.w3.org/WAI/about/projects/wai-guide/">EC-funded WAI-Guide Project</a>.</p>
	</section>

	

</section>


<section id="references" class="appendix"><h2 id="b-references"><bdi class="secno">B. </bdi>References<a class="self-link" aria-label="ยง" href="#references"></a></h2>
  <section id="informative-references">
        <h3 id="b-1-informative-references"><bdi class="secno">B.1 </bdi>Informative references<a class="self-link" aria-label="ยง" href="#informative-references"></a></h3>
      <dl class="bibliography">
        <dt id="bib-en301-549">[EN301-549]</dt><dd><a href="http://mandate376.standards.eu/standard"><cite>Accessibility requirements suitable for public procurement of ICT products and services in Europe</cite></a>.  CEN/CENELEC/ETSI. August 2018. URL: <a href="http://mandate376.standards.eu/standard">http://mandate376.standards.eu/standard</a></dd><dt id="bib-ietf-relay">[ietf-relay]</dt><dd><a href="https://tools.ietf.org/html/draft-rosen-rue-00/"><cite>Interoperability Profile for Relay User EquipmentPI</cite></a>.  IETF. August 5, 2019. URL: <a href="https://tools.ietf.org/html/draft-rosen-rue-00/">https://tools.ietf.org/html/draft-rosen-rue-00/</a></dd><dt id="bib-ietf-rtc">[ietf-rtc]</dt><dd><a href="https://tools.ietf.org/html/rfc7478"><cite>Web Real-Time Communication Use Cases and Requirements</cite></a>.  IETF. March 2015. URL: <a href="https://tools.ietf.org/html/rfc7478">https://tools.ietf.org/html/rfc7478</a></dd><dt id="bib-rtt-sip">[rtt-sip]</dt><dd><a href="https://tools.ietf.org/html/rfc5194"><cite>Framework for Real-Time Text over IP Using the Session Initiation Protocol (SIP)</cite></a>.  IETF, Network Working Group. June 2008. URL: <a href="https://tools.ietf.org/html/rfc5194">https://tools.ietf.org/html/rfc5194</a></dd><dt id="bib-webrtc-priority">[webrtc-priority]</dt><dd><a href="https://w3c.github.io/webrtc-priority/"><cite>WebRTC DSCP Control API</cite></a>.  W3C. 12 February 2020. URL: <a href="https://w3c.github.io/webrtc-priority/">https://w3c.github.io/webrtc-priority/</a></dd><dt id="bib-webrtc-use-cases">[webrtc-use-cases]</dt><dd><a href="https://www.w3.org/TR/webrtc-nv-use-cases/"><cite>WebRTC Next Version Use Cases</cite></a>.  W3C. 11 December 2018. URL: <a href="https://www.w3.org/TR/webrtc-nv-use-cases/">https://www.w3.org/TR/webrtc-nv-use-cases/</a></dd>
      </dl></section></section><p role="navigation" id="back-to-top"><a href="#title"><abbr title="Back to Top">โ</abbr></a></p><script src="https://www.w3.org/scripts/TR/2016/fixup.js"></script></body></html>